{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal - Models of Kepler Exoplanet Classification\n",
    "\n",
    "Logan Correa, u1094034@umail.utah.edu, u1094034\n",
    "\n",
    "Xincen Xi, xincen.xi@utah.edu, u1475541\n",
    "\n",
    "Jiwoo Seo, jiwoo.seo@utah.edu, u1482418\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background and Motivation\n",
    "\n",
    "The alluring mysteries of space have drawn human curiosity since the dawn of mankind. Among these mysteries, the search for life that evolved off our planet has been a driving endeavor in the field of astronomy and astrophysics. The first step in the search for evidence of extraterrestrial life has been to identify exoplanets, or planets that exist beyond our solar system. In 2009, NASA launched the Kepler Space Telescope for this exact purpose. Its primary mission was to survey a section of the Milky Way galaxy to discover Earth-size planets orbiting within their stars' habitable zones. Since its launch, the Kepler mission has provided an unprecedented wealth of data on exoplanets. \n",
    "\n",
    "Our motivation for choosing a project centered on the classification of exoplanets using data from the Kepler Space Telescope stems from a deep-rooted fascination with the universe and the fundamental questions of our existence. This topic lies outside the normal scope of our majors, providing us with a unique opportunity to study a new and interesting subject while also putting into practice the data science skills we have acquired during this course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Objectives\n",
    "\n",
    "The overall objective of the project is to apply machine learning and data analysis techniques to classify and analyze the vast amounts of data collected by the Kepler mission to contribute to our understanding of the universe.\n",
    "\n",
    "The primary objective of this project is to determine classification accuracy; that is, how accurately machine learning algorithms can classify Earth-like exoplanet candidates based on their observed characteristics. This includes identifying which data features are most effective for exoplanet classification. A secondary objective is to utilize our data science skills to determine how we can interpret the results of our models in a meaningful way and visualize the relationships within the data. This objective focuses on developing intuitive visualizations and metrics that can convey complex astronomical concepts in an accessible manner.\n",
    "\n",
    "The benefits of this project include contributing to exoplanet research by enhancing our ability to classify potentially habitable exoplanets, thereby enriching our understanding of the universe and the quest for extraterrestrial life. Additionally, the project offers a chance to improve our machine learning, data preprocessing, and visualization skills through the use of advanced algorithms, handling high-dimensional data, and effectively communicating complex results. This endeavor serves as an opportunity to deepen our knowledge at the confluence of astronomy, data science, and computational methods, paving new paths for research and innovation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description and Acquisition \n",
    "\n",
    "The data is stored in CSV format, which is used for tabulating data. This dataset represents a cumulative record of all observed Kepler \"objects of interest\", it comprises a total of 9564 entries. The dataset encompasses a variety of attributes, including Identification Columns, Exoplanet Archive Information, Project Disposition Columns, Transit Properties, Threshold-Crossing Event (TCE) Information, Stellar Parameters, KIC Parameters, and Pixel-Based KOI Vetting Statistics. It contains extensive information on astronomical objects, such as their locations, luminosities, and physical characteristics. \n",
    "\n",
    "This dataset was published as-is by NASA and was directly downloaded from their website, the links for the dataset is https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=koi. \n",
    "\n",
    "The data descriptions link is\n",
    "https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical Considerations \n",
    "\n",
    "The results of the project could potentially impact astronomers, researchers, academic institutions, and the general public interested in astronomical data.\n",
    "\n",
    "Incorrect analysis or interpretation of data could mislead the public's understanding of space research, potentially affecting research funding and public interest. If the dataset or algorithms used for analysis are biased, the project could reinforce or amplify existing prejudices. Additionally, data could be intentionally manipulated to impact public opinion or policy in adverse ways.\n",
    "\n",
    "“ This research has made use of the NASA Exoplanet Archive, which is operated by the California Institute of Technology, under contract with the National Aeronautics and Space Administration under the Exoplanet Exploration Program.”\n",
    "\n",
    "“The Exoplanet Archive is not designed as a citizen science project, but all data contained in the archive have been published and can be used for additional research with the appropriate acknowledgements.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Processing \n",
    "\n",
    "Data Cleaning: Prior to initiating our analysis, we plan to conduct significant data cleaning efforts to ensure our dataset's quality and reliability. This will include the elimination of records with missing values or outliers and the standardization of data formatting throughout the dataset. \n",
    "\n",
    "Data Extraction: We intend to analyze critical aspects of the data, focusing on the physical and orbital characteristics of planets, as well as their stellar environments. This includes metrics such as planetary sizes, their orbits, and their thermal properties, among other key factors.\n",
    "\n",
    "Data Processing Implementation: \n",
    "\n",
    "We'll employ Python libraries like Pandas for data cleaning, Matplotlib and Seaborn for visualizing trends, and Scikit-learn for preprocessing and training machine learning models. Our process includes data transformation, standardization, and feature selection to meet project objectives and enhance model accuracy. Documentation throughout these steps will ensure our analysis is transparent and replicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis \n",
    "\n",
    "\n",
    "The initial phase of the project involves a comprehensive data summary to provide an overview of the dataset, including the number of records, presence of missing values, and the various data types contained within the dataset. Following the summary, a univariate analysis will be conducted, scrutinizing each variable in isolation. For continuous variables, statistical metrics such as mean, median, standard deviation, variance, and range will be calculated to capture the central tendency and dispersion.\n",
    "\n",
    "To bivariate analysis, we will explore the interactions between each predictor and the exoplanet status. This phase includes assessing potential correlations using Pearson or Spearman correlation coefficients for continuous variables and employing Chi-square tests for associations between categorical features. Scatter plots will facilitate the visualization of potential relationships, and cross-tabulation will allow for the examination of the relationships between categorical variables and the target. Moreover, multivariate analysis will be considered. Dimensionality reduction techniques such as Principal Component Analysis (PCA) will be applied to distill the data.\n",
    "\n",
    "Visualization will be implemented. Histograms, box plots will be utilized for examining distributions and identifying outliers. Heatmaps will be indispensable for illustrating the correlation between variables, while scatter plots and pair plots will offer the relationships and dependencies across multiple dimensions of the dataset.\n",
    "\n",
    "Lastly, we will check the data quality. This encompasses the identification and handling of noise, anomalies, and missing data. Noise reduction strategies may involve smoothing techniques, while anomaly detection could be approached using statistical methods or unsupervised machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Methodology\n",
    "\n",
    "\n",
    "Our classification approach will involve supervised learning models, including Logistic Regression, Support Vector Machines, Decision Trees, and Ensemble Methods like Random Forest and Gradient Boosting, to classify potential exoplanets. For tasks requiring predictions of continuous variables, such as the size of an exoplanet, we'll employ regression models like Linear Regression and Ridge Regression, and even explore Neural Networks for their ability to capture complex, non-linear patterns.\n",
    "\n",
    "Furthermore, unsupervised learning techniques such as K-means and Hierarchical Clustering will aid in uncovering natural groupings in the data, potentially revealing clusters of similar exoplanets or stars. The performance of our models will be rigorously evaluated using metrics appropriate to each task—accuracy, precision, recall, and the F1 score for classification models, and RMSE or R² for regression models.\n",
    "\n",
    "To facilitate understanding and interpretation of the data, we'll apply dimensionality reduction techniques like PCA or t-SNE, which can offer insightful visualizations of the data's structure in reduced dimensions. Finally, we'll focus on model optimization, using cross-validation and hyperparameter tuning methods such as grid search or random search, to ensure that we identify the most effective model for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Schedule\n",
    "\n",
    "\n",
    "**Week 1 & 2 (Until March 15)**\n",
    "\n",
    "Conduct a preliminary review of the Kepler dataset and define project goals.\n",
    "Start drafting the project proposal, outlining objectives, datasets, methods, and anticipated challenges.\n",
    "Submit the project proposal by March 15 at 11:59 pm.\n",
    "\n",
    "**Week 3 & 4 (March 16 - April 3)**\n",
    "\n",
    "Begin detailed data preprocessing: clean data, handle missing values, encode categorical variables.\n",
    "Start exploratory data analysis including univariate and bivariate analysis.\n",
    "Perform initial feature selection and run basic classification models.\n",
    "Write the first milestone report, detailing findings from exploratory data analysis and initial modeling.\n",
    "Submit the first milestone report by April 3 at 11:59 pm.\n",
    "\n",
    "**Week 5 (April 4 - April 10)**\n",
    "\n",
    "Refine machine learning models based on milestone feedback.\n",
    "Expand on feature engineering and selection.\n",
    "Enhance model complexity with more sophisticated algorithms if needed.\n",
    "Ensure model validation using cross-validation and adjust models based on results.\n",
    "\n",
    "**Week 6 (April 11 - April 17)**\n",
    "\n",
    "Finalize all machine learning models and analyses.\n",
    "Begin drafting the final report, incorporating all insights, visualizations, and interpretations.\n",
    "Review preliminary findings and prepare the final report draft.\n",
    "\n",
    "**Week 7 (April 18 - April 19)**\n",
    "\n",
    "Make final edits to the report, ensuring clarity, conciseness, and completeness.\n",
    "Have team members review the final draft.\n",
    "Submit the final project report by April 19 at 11:59 pm.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
